---
title: December 21st, 2019
---

## I scored wayyy below prediction on chem test, and had virtually no idea it would be that bad at any time.

## HPMOR wtf is the game!!!!!

## Eliezer throwing shade on Enders Game! Let's go!

## Harry's brain refused to shut off, just got stupider and stupider

## That was long ago and j have resolved my parental issues to my satisfaction


## 20 what is your ambition: to gain all useful knowledge there is to know, become omnipotent, and use that knowledge to rewrite reality because I have some objections to how it works now

## What evidence would actually convince me that eliezer was bad? I admire him for his fine-grained direct utilitarianism and self-trusting epistemology, and better-than-my intelligence. In direct utilitarianism, there is always some additional evidence, however surprising, that flips the optimal action in any situation. For example, you see someone start nuclear war. That costs billions of lives, lots of scientific progress, and risks extinction.  It is almost certainly terrible. But what if...
### There is already invisible FAGI which discovers extraterrestrials, and decides to fake humanity's death to avoid threatening the extraterrestrials so it can spread to other galaxies still unseen  and generate LOTS of utils?

### Someone else was about to start it, and would have caused a worse outcome

### Somehow biological evolution of humans is necessary, and nuclear war will increase the rate of natural selection and improve us

## Not that those are good, but they theoretically could change the logic

## So anyway, let's say I see someone shoot a random guy on the street. My hypothesis pool might be
### The person is a suicidal shooter, personal or religious

### The person is 

## But if it's eliezer,
### This could be the result of a complex utility calculation whose info I don't know, and whose logic I cant quickly check. Even if I saw similar things repeatedly, there could be common threads that make all good.

## 
