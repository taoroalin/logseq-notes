---
title: January 1st, 2020
---

## Legit value of altered states of consciousness: example of aphantasia https://m.facebook.com/notes/blake-ross/aphantasia-how-it-feels-to-be-blind-in-your-mind/10156834777480504/
### Don't other people with extreme verbal IQ also have aphantasia?
#### Jordan Peterson does

#### Moderate to strong evidence that a huge percentage of extreme verbal iq people have it.

## Great [[Yudkowsky]] interview https://blogs.scientificamerican.com/cross-check/ai-visionary-eliezer-yudkowsky-on-the-singularity-bayesian-brains-and-closet-goblins/
### You can run into what we call "The Valley of Bad Rationality."  If you were previously irrational in multiple ways that balanced or canceled out, then becoming half-rational can leave you worse off than before.  Becoming incrementally more rational can make you incrementally worse off, if you choose the wrong place to invest your skill points first.

### Even though adding on additional details necessarily makes a story less probable, it can make the story sound more plausible.  I see understanding this as a kind of Pons Asinorum of serious futurism - the distinction between carefully weighing each and every independent proposition you add to your burden, asking if you can support that detail independently of all the rest, versus making up a wonderful vivid story.

### Human intelligence is privileged mainly by being the least possible level of intelligence that suffices to construct a computer; if it were possible to construct a computer with less intelligence, we'd be having this conversation at that level of intelligence instead.

### With sufficient knowledge you might be able to reach into that space of possibilities and deliberately pull out an AI that wanted things that had a compact description in human wanting-language, but that wouldn't be because this is a kind of thing that those exotic superintelligence people naturally want, it would be because you managed to pinpoint one part of the design space.
