---
title: January 4th, 2020
---

## [[Yudkowsky]] https://www.lesswrong.com/posts/ZmDEbiEeXk3Wv2sLH/emotional-involvement https://www.lesswrong.com/posts/W5PhyEQqEWTcpRpqn/dunbar-s-function
### Though it's a side issue, what's even more... interesting.... is the way that our brains simply __haven't updated__ to their diminished power in a super-Dunbarian world.  We just go on debating [politics](https://www.lesswrong.com/lw/gw/politics_is_the_mindkiller/), feverishly applying our valuable brain time to finding better ways to run the world, with just the same fervent intensity that would be appropriate if we were in a small tribe where we could persuade people to change things.

### But it does not seem to me, that a mind which __has__ the most value, is the same kind of mind that most __efficiently optimizes__ values outside it.  The interior of a true expected utility maximizer might be pretty boring, and I even suspect that you can [build them to not be sentient](https://www.lesswrong.com/lw/x7/cant_unbirth_a_child/).

## [[Yudkowsky]]'s Coming of Age!
### https://www.lesswrong.com/posts/uD9TDHPwQ5hx4CgaX/my-childhood-death-spiral

### [[Self Improvement]] Looking back, it seems to me that quite a lot of my mistakes can be defined in terms of being [pushed too far in the other direction](https://www.lesswrong.com/lw/lw/reversed_stupidity_is_not_intelligence/) by seeing someone else stupidity

### I was under no such illusion and quite reluctant to learn to drive, considering how unsafe those hurtling hunks of metal looked.  But there was something more important to me than my own life:  The Future.  And I acted as if __that__ was immortal.  Lives could be lost, but not the Future.
#### This resonates so hard

### https://www.lesswrong.com/posts/AdYdLP2sRqPMoe8fb/knowing-about-biases-can-hurt-people
#### Once upon a time I tried to tell my mother about the problem of expert calibration, saying: “So when an expert says they’re 99% confident, it only happens about 70% of the time.” Then there was a pause as, suddenly, I realized I was talking to my mother, and I hastily added: “Of course, you’ve got to make sure to apply that skepticism evenhandedly, including to yourself, rather than just using it to argue against anything you disagree with—”

#### Whether I do it on paper, or in speech, I now try to never mention calibration and overconfidence unless I have first talked about disconfirmation bias, motivated skepticism, sophisticated arguers, and dysrationalia in the mentally agile. First, do no harm!

#### 

## Cached Thoughts
### Dear God, I know that religions are not allowed to have any falsifiable consequences, which means that you can’t possibly heal my daughter, so . . . well, basically, I’m praying to make myself feel better, instead of doing something that could actually help my daughter.

### It’s frustrating, talking to good and decent folk—people who would never in a thousand years __spontaneously__ think of wiping out the human species—raising the topic of existential risk, and hearing them say, “Well, maybe the human species doesn’t deserve to survive.” They would never in a thousand years shoot their own child, who is a part of the human species, but the brain completes the pattern.
