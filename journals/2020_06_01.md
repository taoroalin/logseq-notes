---
title: June 1st, 2020
---

## [[Sam Altman]]: "When ai can say 'You said X, but I think you really meant Y' and be right most of the time, that's the time to be worried [about agi]"
### Disagree. Most people's mistakes can be corrected by population average methods. Agi would be able to correct an interesting person talking about very novel things

## How does one remember all the #Haskell category theory operators?
### Functor
#### Functor Apply `(<$>) = fmap`

#### Functor Replace`(<$) = fmap . const`

#### Functor Replace Backword `($>) = flip $ fmap . const`

### Applicative

### (<>) = Asociative Binary Operation

### `<|> = Alternative Composition

## #UDASSACTAA ethical system
### Universal Distribution Absolute Self Sampling Assumption Acausal Trade Aggregation Approximation

### Universally Distributed Acausal Trade Approximation

## There should be a podcast called Questionable Ontology (or something) that's about all things acausal, out-of-universe, untestable, and otherwise reality-bending

## 
