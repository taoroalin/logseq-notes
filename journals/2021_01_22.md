---
title: January 22nd, 2021
---

## [[Elianna]] I disagree with the idea of studying complexity in university. I think the best way to understand a complex system is to work as an ordinary agent within that system, and build abstractions based on experience. I'm talking about spending years inside, not above, the system you're trying to understand, and then coming up with an abstraction or treatment for it.

## bad blog post I read https://mule.substack.com/p/lithographyandasml

## Idea for "programming in general" -- assuming it were productive to have such ideas ???
### Out of all the "generalized" ways of storing information, such as objects, structs, immutable persistant datastructures, ect, Datomic/[[Datascript]] are the most general. What if there was a language where **100% of memory that lasts between frames / requests was stored in** [[Datascript]]. 

## [[Performance]]
:PROPERTIES:
:ID:82f69bec-11de-408d-9f95-d894f394ec20
:END:
### I don't want to fucking hear how "high performance" your shit is. In most cases, I already know what computation needs to happen. There's nothing magic you can add to your system to make it faster. All you can do is just spend more cpu cycles on the things I care about and fewer on stupid shit.

### {{embed ((82f69bec-11de-408d-9f95-d894f394ec20))}}

### 

## [[CRUD]][[7 GUIs]][[Performance]]
### Here are all the different data structures / algorithms I used on my journey to searching 1,000,000 names in ClojureScript
#### Used cljs vector, filtered for names every render. This didn't even get to 10,000.

#### Use my own trie (based on cljs maps). This was slightly faster, but still only 10,000. It used way too much memory, took too much time to construct

#### Used sorted-set, found names starting with prefix with cljs rsubseq. This got up to 100,000 names and starts in a few seconds.

#### Switch to tonsky's sorted set (something like double performance of normal sorted-set). Switched from randomly generated names to names generated in alphabetical order to avoid needing to sort (much performance). Switch from `(range 1000000)` to `[...Array(1000000).keys()]` (about double performance). Now it works with 1,000,000 names, and starts in ~1 second. It has performance issues clearing thousands of names from the DOM, likely because of the indexing Reagent is doing.
##### [[Tonsky]] is legit. His blog posts about performance are awesome, and his code's performance backs that up!

##### My code here is still fairly reasonable clojurescript code. Not so for the next step ;)

##### ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fgraphminer%2FzhLDS9wIIj.png?alt=media&token=63e58182-9ca3-4f3e-9c39-0411adbe7e4a)
###### This is a small section of the name generation. A lot of time is spent on GC. Need to reduce this if it's gonna get to 10,000,000

#### (haven't finished this yet) Go full hardcore mode. We're writing this like it's fucking 1980 and we have 2k ram. Limit names to 32 chars, and store them in sorted order in ArrayBuffer. Instead of updating array buffer, store updates in seperate data structure. render by integrating both. Don't use reagent to render name list. Instead, generate the 20 names that fit on the screen myself whenever anything changes. (could keep using reagent if I got it to stop storing old DOM nodes. Or I could stop using keys and just make sure I render few names at once :) This can get 10x RAM usage and 100x performance.

#### Let's say my life depended on cramming as many names as possible into the browser. Then I would have the names stored on the server 1,000 chunks, each of which is names from a certain range of the dictionary (think encyclopedia), that are stored with Brotli compression (like gzip but better). The client stores them with service worker.  When the user searches, it decompresses the block with the right range, and binary searches in it. The chunks would be lazy loaded into the client. If each name is on average 16 bytes, and english text compression is 10x, and because sorted names are more repetitive than normal text for an extra 3x compression, then 1,000,000,000 names would take up 500M space on your computer. Theoretically you could use up 5G storage and have 10,000,000,000 names.
:PROPERTIES:
:ID:a35fe827-fec4-47ed-b153-14c1f7751a97
:END:
##### Is a list of names higher or low

#### Fuck that. Let's make this more specific. Let's say you had a list of all the documented people in the world (like 5 billion), that you updated infrequently (like yearly), and you wanted to search it in-browser. Then I would use compressed blocks like [6](((a35fe827-fec4-47ed-b153-14c1f7751a97))), but use a custom binary file format to store consecutive names more efficiently. It would be based on a [[Trie]], and look something like this
##### ```c
char next_char_offset char ```

### lol 50 random names? I need 100,000,000 names!
#### ![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fgraphminer%2FCXrK5GEDfK.png?alt=media&token=91736034-6530-4be6-87ce-2f86bdbbdba7)

## https://www.metaculus.com/news/2020/11/17/hiring/ [[Applications]][[Future Options]] maybe next time

## [[Roam]][[Improvements]] don't show autocomplete while typing https://

## [[Coding Streamers]] There are actually some decent coding streamers out there. My favorite are:
### [[Jonathan Blow]] [[George Hotz]] [[Tsoding]][[Strager]] https://www.twitch.tv/onelivesleft

## YES FUCKING [[SlateStarCodex]] is back!!!!!! https://astralcodexten.substack.com/p/still-alive https://astralcodexten.substack.com/p/still-alive https://astralcodexten.substack.com/p/still-alive https://astralcodexten.substack.com/p/still-alive https://astralcodexten.substack.com/p/still-alive https://astralcodexten.substack.com/p/still-alive https://astralcodexten.substack.com/p/still-alive https://astralcodexten.substack.com/p/still-alive https://astralcodexten.substack.com/p/still-alive https://astralcodexten.substack.com/p/still-alive https://astralcodexten.substack.com/p/still-alive https://astralcodexten.substack.com/p/still-alive https://astralcodexten.substack.com/p/still-alive https://astralcodexten.substack.com/p/still-alive https://astralcodexten.substack.com/p/still-alive https://astralcodexten.substack.com/p/still-alive https://astralcodexten.substack.com/p/still-alive https://astralcodexten.substack.com/p/still-alive https://astralcodexten.substack.com/p/still-alive
### Oh it makes more sense now!
#### "Maybe I should explain more of my history here: back in the early 2010s I blogged under my real name. When I interviewed for my dream job in psychiatry, the interviewer had Googled my name, found my blog, and asked me some really pointed questions about whether having a blog meant I was irresponsible and unprofessional. There wasn't even anything controversial on the blog - this was back in the early 2010s, before they invented controversy. They were just old-school pre-social-media-era people who thought having a blog was fundamentally incompatible with the dignity of being a psychiatrist. I didn't get that job, nor several others I thought I was a shoo-in for. I actually failed my entire first year of ACGME match and was pretty close to having to give up on a medical career. At the time I felt like that would mean my life was over."

### I was thinking about ways to reduce the influence of the Times, and actually I think Denial-Of-Service attacks would probably be enough! It's definitely feasible to shut down their site for 90% of the next year, and I don't see how they would recover from that!

## https://computers-are-fast.github.io/
### https://gist.github.com/jboner/2841832
#### ![computer speed](https://i.imgur.com/k0t1e.png)

#### 
